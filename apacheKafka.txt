Seccion 1 Intro
	Kafka es un sistema de mensajeria


	Productor
		v
	  Kafka
		v
	Consumidor
	  
	 Productor: Se pueden depositar mensajes de cualquier formato de datos en forma de eventos

	 Consumidor: También pueden ser cualquier sustem como base de datos o herramientas analíticas.

	Escrito en Java y Scala, creado en Linkedin donado a Apache software Foundations
	COmpite con Cloudera

	Usado por linkedin, Uber, Netflix
	
	Contruir flujos de datos en tiempo real, procesamiento en stream, gestion de logs
	sistemas de recomendación en tiempo real, recolección de datos en tiempo real.
	

Sección 2
	- Modelo Editor-Subscriptor (bus de mensajería)
		- Suscriptor incorpora un filtro para tomar eventos de interes (topics)
		- Editor genera eventos
		- Paradigma asincrono
		- Suscriptor recibe evento, se le llama push
		- Subscritpro pregunta por eventos pull
		- Hibridos
		
	Brokers intemediarios
		- Enrutan los mensajes
		- Desacoplan las aplicaciones
		- Organizan y comprueban los mensajes
		- Almacenan los mensajes
		
Kafka
	- Productores
	- Broker
	- Consumidores
	
Plataforma de sreaming
- Kafka Streams 
- Kafka Connect
- Ksql
- Scheme Registry 

Topics:
	- Categorias en donde se van a clasificar los mensajes almacenados, un topic es como
	un flujo de datos, se puede crear todos los topics que necesitemos
	- los mensajes son persistidos en disco
	- pueden existir réplicas de las particiones
	- tiempo de retencion de los mensajes en disco es configurable
	- el rendimiento de kafka es constante
		- no importa la cantidad ni tamaño de los datos persistidos
		
		
Para identificar un mensaje necesitamos
	- Nombre del topic
	- Partición
	- Offset
		
Apache Kafka usa Zookeper para almacenar metadatos en cluster de Kafka y detalles de los
   consumidores. 
   - Antes de instalar kafka se debe instalar un cluster de zookeper
		
		
Comandos para Apache Kafka
Ejecutar Zookeeper:
	> ./bin/zookeeper-server-start.sh config/zookeeper.properties

Ejecutar Broker de Kafka:
	> ./bin/kafka-server-start.sh config/server.properties

Crear un topic de Kafka con factor de replicación de 3 y dos particiones:
	> /bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 3 --partitions 2 --topic testtopic

Visualizar detalles de un topic de Kafka:
	> /bin/kafka-topics.sh --describe --zookeeper localhost:2181 --topic testtopic

Listar los topics de Kafka:
	> ./bin/kafka-topics.sh --list --zookeeper localhost:2181

Ejecutar consumidor de consola de Kafka sobre un topic:
	> /bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic testtopic --group grupo1

Ejecutar productor de consola de Kafka sobre un topic:
	> ./bin/kafka-console-producer.sh --broker-list localhost:9092,localhost:9093,localhost:9094 --topic testtopic

Describir los grupos de consumidores en Kafka:
	> ./bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --group grupo1 --describe

Ejecutar Kafka Mirror Maker sobre un topic con la configuración del consumidor y productor:
	> ./bin/kafka-mirror-maker.sh --consumer.config config/consumer.properties --producer.config config/producer.properties --whitelist testtopic



Kafka topics
	1.- Crear topics
		Factor replicación recimendado = 3 , máximo 4
		
		
	Replicas: son la lista de nodos	
	
Un broker es un nodo de apache Kafka (broker= corredor o agente)

Productores: publica mensajes en un broker
	- Serializar
	- Particionar
	- Comprimir
	- Repartir Carga
	Eligen que mensaje asignar a que topic

Mensaje:
	compuesto por 
	- Clave
	- Valor
	- Timestamp
	- Máximo 1Mb (configurable message.bax.bytes)
	
Bootstrap Servers
	- Lista de brokers para que los productores conecten con Kafka
	- Establece conexiones con servidor de bootstrap
	- Devuelve lista con:
		- Brokers disponibles
		- Topics
		- Particiones
		- Réplicas
	- Identificar el líder de la partición
	- Envía los Datos
	
Escritura por parte del productor incluye 5 pasos
	- Serialización
	- Particionado
	- Compresión
	- Acumulación
	- Agrupación
	
Consumidores y grupo de consumidores
	. Clientes suscritos a topics que consumen mensajes
	- Cada mensaje es leido por solo un consumidor de cada grupo
	
Modelo de mensajería
	- cola de mensajes (consume un consumidor)
	- Editor/Suscriptor (se difunde a todos los consumidores del topic)
	- Grupo de consumidores (ambos anteriores) 
	
No puede haber más consumidores que particiones

Garantia de entrega
- Exactly-once
- At-most-once
- Atleast-one

Que son las transacciones?
	- Permiten escritura atomica a topics y particiones
	- Todos los mensajes incluidos en la transaccion serán escritos con exito o ninguno lo será
	
	

Seccion 3 Desarrollo con Kafka
	
	
	Código para Apache Kafka
Bloques de Código en Java de ejemplos Kafka
Ejemplo de pom.xml:

<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://maven.apache.org/POM/4.0.0
http://maven.apache.org/xsd/maven-4.0.0.xsd">
    <modelVersion>4.0.0</modelVersion>
    <groupId>org.example</groupId>
    <artifactId>tests-kafka</artifactId>
    <version>1.0-SNAPSHOT</version>
    <properties>
        <maven.compiler.source>1.8</maven.compiler.source>
        <maven.compiler.target>1.8</maven.compiler.target>
    </properties>
 
    <dependencies>
        <dependency>
            <groupId>org.apache.kafka</groupId>
            <artifactId>kafka-clients</artifactId>
            <version>2.6.0</version>
        </dependency>
        <dependency>
            <groupId>com.fasterxml.jackson.core</groupId>
            <artifactId>jackson-databind</artifactId>
            <version>2.11.3</version>
        </dependency>
    </dependencies>
</project>


Consumidor simple de Kafka:

import org.apache.kafka.clients.consumer.ConsumerConfig;
import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.apache.kafka.clients.consumer.ConsumerRecords;
import org.apache.kafka.clients.consumer.KafkaConsumer;
import java.time.Duration;
import java.util.Collections;
import java.util.Properties;
 
public class Consumidor {
    public static void main(String[] args) {
    Properties props = new Properties();
    props.put("key.deserializer","org.apache.kafka.common.serialization.StringDeserializer");
    props.put("value.deserializer","org.apache.kafka.common.serialization.StringDeserializer");
    props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG,"localhost:9092,localhost:9093,localhost:9094");
    props.put("group.id", "grupo1");
    props.put("enable.auto.commit", "true");
    props.put("auto.commit.interval.ms", "1000");
    props.put("fetch.min.bytes", "1");
    props.put("fetch.max.wait.ms", "500");
    props.put("max.partition.fetch.bytes", "1048576");
    props.put("session.timeout.ms", "10000");
    
    KafkaConsumer<String, String> consumer = new KafkaConsumer<String,String>(props);
 
    try{
        consumer.subscribe(Collections.singletonList("topic-test"));
        
        while (true) {
        ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds(10));
 
            for (ConsumerRecord<String, String> record : records){
                System.out.print("Topic: " + record.topic() + ", ");
                System.out.print("Partition: " + record.partition() + ",");
 
                System.out.print("Key:" + record.key() + ", ");
                System.out.println("Value: " + record.value() + ", ");
            }
          }
        } catch (Exception e){e.printStackTrace();}
        
        finally {
        consumer.close();}
     }
}


Productor simple de Kafka:

import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.ProducerConfig;
import org.apache.kafka.clients.producer.ProducerRecord;
import java.util.Properties;
 
public class Productor {
 
    public static void main(String[] args) {
 
        Properties props = new Properties();props.put("key.serializer","org.apache.kafka.common.serialization.StringSerializer");
        props.put("value.serializer","org.apache.kafka.common.serialization.StringSerializer");
        props.put("acks", "all");
        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG,"localhost:9092,localhost:9093,localhost:9094");
        props.put("retries", 0);
        props.put("batch.size", 16384);
        props.put("buffer.memory", 33554432);
 
        KafkaProducer<String, String> prod = new KafkaProducer<>(props);
        String topic = "topic-test";
        int partition = 0;
        String key = "testKey";
        String value = "testValue";
        prod.send(new ProducerRecord<>(topic,partition,key, value));
        prod.close();
     }
}


Productor simple de Kafka con función callback:

import org.apache.kafka.clients.producer.*;
import java.util.Properties;
 
public class Productor {
 
    public static void main(String[] args) {
 
        Properties props = new Properties();
        props.put("key.serializer","org.apache.kafka.common.serialization.StringSerializer");
        props.put("value.serializer","org.apache.kafka.common.serialization.StringSerializer");
        props.put("acks", "all");
        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG,"localhost:9092,localhost:9093,localhost:9094");
        props.put("retries", 0);
        props.put("batch.size", 16384);
        props.put("buffer.memory", 33554432);
        
        KafkaProducer<String, String> prod = new KafkaProducer<>(props);
        String topic = "topic-test";
        int partition = 0;
        String key = "testKey";
        String value = "testValue";
        final ProducerRecord<String, String> record = new
ProducerRecord<>(topic, key, value);
        prod.send(record, new Callback() {
            public void onCompletion(RecordMetadata metadata, Exception e) {
                if (e != null) {
                    System.out.println("Send failed for record");
                }
            }
        });
 
    prod.close();
    }
}